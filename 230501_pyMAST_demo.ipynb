{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for the implementation of a MAST-like model for DEG using `PyTorch`\n",
    "\n",
    "- **Developed by**: Carlos Talavera-López Ph.D\n",
    "- **Institute of Computational Biology - Computational Health Centre - Helmholtz Munich**\n",
    "- v230501"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from tqdm import trange\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "anndata     0.9.1\n",
      "scanpy      1.9.3\n",
      "-----\n",
      "PIL                 9.4.0\n",
      "appnope             0.1.3\n",
      "asttokens           NA\n",
      "backcall            0.2.0\n",
      "beta_ufunc          NA\n",
      "binom_ufunc         NA\n",
      "cffi                1.15.1\n",
      "colorama            0.4.6\n",
      "comm                0.1.3\n",
      "cycler              0.10.0\n",
      "cython_runtime      NA\n",
      "dateutil            2.8.2\n",
      "debugpy             1.6.7\n",
      "decorator           5.1.1\n",
      "executing           1.2.0\n",
      "gmpy2               2.1.2\n",
      "h5py                3.8.0\n",
      "hypergeom_ufunc     NA\n",
      "igraph              0.10.4\n",
      "invgauss_ufunc      NA\n",
      "ipykernel           6.22.0\n",
      "jedi                0.18.2\n",
      "joblib              1.2.0\n",
      "kiwisolver          1.4.4\n",
      "leidenalg           0.9.1\n",
      "llvmlite            0.39.1\n",
      "matplotlib          3.7.1\n",
      "mpl_toolkits        NA\n",
      "mpmath              1.3.0\n",
      "natsort             8.3.1\n",
      "nbinom_ufunc        NA\n",
      "ncf_ufunc           NA\n",
      "nct_ufunc           NA\n",
      "ncx2_ufunc          NA\n",
      "numba               0.56.4\n",
      "numpy               1.23.5\n",
      "packaging           23.1\n",
      "pandas              2.0.1\n",
      "parso               0.8.3\n",
      "pexpect             4.8.0\n",
      "pickleshare         0.7.5\n",
      "pkg_resources       NA\n",
      "platformdirs        3.5.0\n",
      "prompt_toolkit      3.0.38\n",
      "psutil              5.9.5\n",
      "ptyprocess          0.7.0\n",
      "pure_eval           0.2.2\n",
      "pydev_ipython       NA\n",
      "pydevconsole        NA\n",
      "pydevd              2.9.5\n",
      "pydevd_file_utils   NA\n",
      "pydevd_plugins      NA\n",
      "pydevd_tracing      NA\n",
      "pygments            2.15.1\n",
      "pyparsing           3.0.9\n",
      "pytz                2023.3\n",
      "scipy               1.10.1\n",
      "session_info        1.0.0\n",
      "setuptools          67.7.2\n",
      "six                 1.16.0\n",
      "skewnorm_ufunc      NA\n",
      "sklearn             1.2.2\n",
      "stack_data          0.6.2\n",
      "sympy               1.11.1\n",
      "texttable           1.6.7\n",
      "threadpoolctl       3.1.0\n",
      "torch               2.0.0\n",
      "tornado             6.3\n",
      "tqdm                4.65.0\n",
      "traitlets           5.9.0\n",
      "typing_extensions   NA\n",
      "wcwidth             0.2.6\n",
      "zmq                 25.0.2\n",
      "zoneinfo            NA\n",
      "-----\n",
      "IPython             8.13.1\n",
      "jupyter_client      8.2.0\n",
      "jupyter_core        5.3.0\n",
      "-----\n",
      "Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:12:31) [Clang 14.0.6 ]\n",
      "macOS-12.5.1-arm64-arm-64bit\n",
      "-----\n",
      "Session information updated at 2023-05-01 22:28\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1769)\n",
    "\n",
    "sc.settings.verbosity = 3\n",
    "sc.logging.print_versions()\n",
    "sc.settings.set_figure_params(dpi = 180, color_map = 'magma_r', dpi_save = 300, vector_friendly = True, format = 'svg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 97573 × 27208\n",
       "    obs: 'sex', 'age', 'ethnicity', 'PaCO2', 'donor', 'infection', 'disease', 'SMK', 'illumina_stimunr', 'bd_rhapsody', 'n_genes', 'doublet_scores', 'predicted_doublets', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'percent_mt2', 'n_counts', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'condition', 'sample_group', '_scvi_batch', '_scvi_labels', 'IAV_score', 'group', 'C_scANVI', 'cell_type', 'leiden', 'leiden_states'\n",
       "    var: 'mt', 'ribo', 'n_cells_by_counts-V1', 'mean_counts-V1', 'pct_dropout_by_counts-V1', 'total_counts-V1', 'n_cells_by_counts-V2', 'mean_counts-V2', 'pct_dropout_by_counts-V2', 'total_counts-V2', 'n_cells_by_counts-V3', 'mean_counts-V3', 'pct_dropout_by_counts-V3', 'total_counts-V3', 'n_cells_by_counts-V4', 'mean_counts-V4', 'pct_dropout_by_counts-V4', 'total_counts-V4', 'n_cells_by_counts-V5', 'mean_counts-V5', 'pct_dropout_by_counts-V5', 'total_counts-V5', 'n_cells_by_counts-V6', 'mean_counts-V6', 'pct_dropout_by_counts-V6', 'total_counts-V6', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n",
       "    uns: 'C_scANVI_colors', 'cell_type_colors', 'disease_colors', 'group_colors', 'infection_colors', 'leiden', 'leiden_colors', 'leiden_states_colors', 'neighbors', 'seed_labels_colors'\n",
       "    obsm: 'X_scANVI', 'X_scVI', 'X_umap'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad('./data/Marburg_All_ctl230404_leiden_states.raw.h5ad')\n",
    "adata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Highly Variable Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you pass `n_top_genes`, all cutoffs are ignored.\n",
      "extracting highly variable genes\n",
      "--> added\n",
      "    'highly_variable', boolean vector (adata.var)\n",
      "    'highly_variable_rank', float vector (adata.var)\n",
      "    'means', float vector (adata.var)\n",
      "    'variances', float vector (adata.var)\n",
      "    'variances_norm', float vector (adata.var)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 97573 × 1500\n",
       "    obs: 'sex', 'age', 'ethnicity', 'PaCO2', 'donor', 'infection', 'disease', 'SMK', 'illumina_stimunr', 'bd_rhapsody', 'n_genes', 'doublet_scores', 'predicted_doublets', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'percent_mt2', 'n_counts', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'condition', 'sample_group', '_scvi_batch', '_scvi_labels', 'IAV_score', 'group', 'C_scANVI', 'cell_type', 'leiden', 'leiden_states'\n",
       "    var: 'mt', 'ribo', 'n_cells_by_counts-V1', 'mean_counts-V1', 'pct_dropout_by_counts-V1', 'total_counts-V1', 'n_cells_by_counts-V2', 'mean_counts-V2', 'pct_dropout_by_counts-V2', 'total_counts-V2', 'n_cells_by_counts-V3', 'mean_counts-V3', 'pct_dropout_by_counts-V3', 'total_counts-V3', 'n_cells_by_counts-V4', 'mean_counts-V4', 'pct_dropout_by_counts-V4', 'total_counts-V4', 'n_cells_by_counts-V5', 'mean_counts-V5', 'pct_dropout_by_counts-V5', 'total_counts-V5', 'n_cells_by_counts-V6', 'mean_counts-V6', 'pct_dropout_by_counts-V6', 'total_counts-V6', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n",
       "    uns: 'C_scANVI_colors', 'cell_type_colors', 'disease_colors', 'group_colors', 'infection_colors', 'leiden', 'leiden_colors', 'leiden_states_colors', 'neighbors', 'seed_labels_colors', 'hvg'\n",
       "    obsm: 'X_scANVI', 'X_scVI', 'X_umap'\n",
       "    layers: 'counts'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_raw = adata.copy()\n",
    "adata.layers['counts'] = adata.X.copy()\n",
    "\n",
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    flavor = \"seurat_v3\",\n",
    "    n_top_genes = 1500,\n",
    "    layer = \"counts\",\n",
    "    batch_key = \"donor\",\n",
    "    subset = True\n",
    ")\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing counts per cell The following highly-expressed genes are not considered during normalization factor computation:\n",
      "['AC105402.3', 'ACTG1', 'ADGRF5', 'AGBL4', 'AGR2', 'AKR1B1', 'ALDH1A1', 'ALDH3A1', 'ANXA1', 'ANXA2', 'AQP3', 'AREG', 'ASCL3', 'ATF3', 'ATP12A', 'AZGP1', 'B2M', 'BIRC3', 'BPIFA1', 'BPIFB1', 'C15orf48', 'C3', 'CA12', 'CAMK2N1', 'CAV1', 'CAVIN1', 'CCL20', 'CCND1', 'CD74', 'CDC20B', 'CDH6', 'CEACAM6', 'CLDN4', 'CLU', 'COL1A1', 'CRYM', 'CSTA', 'CXCL1', 'CXCL10', 'CXCL11', 'CXCL14', 'CXCL17', 'CXCL2', 'CXCL6', 'CXCL8', 'CYB5A', 'DST', 'ELF3', 'FABP5', 'FGFBP1', 'FN1', 'GADD45B', 'GAPDH', 'GDF15', 'GJB2', 'GRIP1', 'GSN', 'GSTA2', 'H1F0', 'HLA-B', 'HMOX1', 'HSP90AA1', 'IFI6', 'IFIT1', 'IFIT2', 'IFIT3', 'IGFBP3', 'IGFBP5', 'IGFBP7', 'IL17C', 'IL1B', 'IRF1', 'ISG15', 'ITGB1', 'KLK10', 'KLK7', 'KRT13', 'KRT15', 'KRT17', 'KRT4', 'KRT5', 'KRT6A', 'KRT6B', 'KRT7', 'LAMA3', 'LAMB3', 'LAMC2', 'LCN2', 'LTF', 'MALAT1', 'MAP1B', 'MMP10', 'MMP13', 'MMP7', 'MMP9', 'MSMB', 'MT1G', 'MT1X', 'MT2A', 'MUC16', 'MUC4', 'MUC5AC', 'NC_026431.1', 'NC_026432.1', 'NC_026433.1', 'NC_026434.1', 'NC_026435.1', 'NC_026436.1', 'NC_026437.1', 'NC_026438.1', 'NPC2', 'NR1D1', 'NREP', 'OLFM4', 'PEG10', 'PFN1', 'PI3', 'PIGR', 'PLAU', 'PSCA', 'RARRES1', 'RHOB', 'RNASE1', 'S100A2', 'S100A4', 'S100A7', 'S100A8', 'S100A9', 'S100P', 'SAA1', 'SAA2', 'SAT1', 'SCG2', 'SCGB1A1', 'SCGB3A1', 'SELENOP', 'SERPINB1', 'SERPINB2', 'SERPINB3', 'SERPINB4', 'SERPINE1', 'SFN', 'SFTPB', 'SLC34A2', 'SLPI', 'SOD2', 'SPP1', 'SPRR1B', 'SPRR3', 'ST18', 'STATH', 'TAGLN', 'TENM2', 'TF', 'TFCP2L1', 'THBS1', 'TIMP1', 'TIMP3', 'TINAGL1', 'TNFSF10', 'TPM1', 'TPPP3', 'TUBA1B', 'VIM', 'WFDC2']\n",
      "    finished (0:00:00)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.normalize_total(adata, exclude_highly_expressed = True, target_sum = 1e6)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One-hot encode cell types, conditions, and batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cell_types = pd.get_dummies(adata.obs['leiden_states'], prefix = 'leiden_states')\n",
    "conditions = pd.get_dummies(adata.obs['group'], prefix = 'group')\n",
    "batches = pd.get_dummies(adata.obs['batch'], prefix = 'batch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Concatenate the one-hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.concat([cell_types, conditions, batches], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Convert the metadata to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_tensor = torch.tensor(metadata.values, dtype = torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Combine the expression data with the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = adata.X.toarray() if adata.X.__class__.__name__ == 'csr_matrix' else adata.X\n",
    "X = torch.tensor(X_dense, dtype = torch.float32)\n",
    "X_combined = torch.cat([X, metadata_tensor], dim = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HurdleModel(nn.Module):\n",
    "    def __init__(self, n_genes, n_metadata, n_outputs):\n",
    "        super(HurdleModel, self).__init__()\n",
    "        self.logistic_regression = nn.Sequential(\n",
    "            nn.Linear(n_genes + n_metadata, n_outputs),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.linear_regression = nn.Sequential(\n",
    "            nn.Linear(n_genes + n_metadata, n_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        zero_inflation = self.logistic_regression(x)\n",
    "        positive_expression = self.linear_regression(x)\n",
    "        return zero_inflation, positive_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAST(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MAST, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        zero_inflation = torch.sigmoid(self.fc3(x))\n",
    "        positive_expression = F.relu(self.fc3(x))\n",
    "        return zero_inflation, positive_expression\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = X.shape[1]\n",
    "n_metadata = metadata_tensor.shape[1]\n",
    "n_outputs = len(adata.obs['leiden_states'].cat.categories) * len(adata.obs['group'].cat.categories)\n",
    "model = HurdleModel(n_genes, n_metadata, n_outputs)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the combined input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X_combined, targets_zero_inflation, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        permutation = torch.randperm(X_combined.size()[0])\n",
    "        \n",
    "        for i in range(0, X_combined.size()[0], batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = X_combined[indices], targets_zero_inflation[indices]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            zero_inflation, positive_expression = model(batch_x)\n",
    "            \n",
    "            loss_zero_inflation = nn.BCELoss()(zero_inflation, batch_y)\n",
    "            loss_positive_expression = nn.MSELoss()(positive_expression, batch_y)\n",
    "            \n",
    "            loss = loss_zero_inflation + loss_positive_expression\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zero_inflation_targets(adata, threshold=0.5):\n",
    "    zero_inflation_targets = []\n",
    "\n",
    "    for i, row in tqdm(adata.obs.iterrows(), total=adata.obs.shape[0], desc=\"Calculating zero inflation targets\", bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % ('\\033[1;34m', '\\033[0m')):\n",
    "        cell_type = row['leiden_states']\n",
    "        condition = row['group']\n",
    "\n",
    "        # Filter data based on cell type and condition\n",
    "        subset = adata[(adata.obs['leiden_states'] == cell_type) & (adata.obs['group'] == condition), :]\n",
    "\n",
    "        # Calculate the proportion of zero values for each gene\n",
    "        proportions = (subset.X.A != 0).mean(axis = 0)\n",
    "\n",
    "        # Determine if a gene is considered \"zero-inflated\" based on the threshold\n",
    "        zero_inflated = (1 - proportions > threshold).astype(float)\n",
    "\n",
    "        zero_inflation_targets.append(zero_inflated)\n",
    "\n",
    "    # Stack the zero-inflation targets into a single tensor\n",
    "    zero_inflation_targets = torch.tensor(np.vstack(zero_inflation_targets)[:, :adata.shape[1]], dtype = torch.float32)\n",
    "\n",
    "    return zero_inflation_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating zero inflation targets: 100%|\u001b[1;34m██████████\u001b[0m| 97573/97573 [17:55<00:00, 90.69it/s] \n"
     ]
    }
   ],
   "source": [
    "targets_zero_inflation = calculate_zero_inflation_targets(adata, threshold = 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definie training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X_combined, targets_zero_inflation, epochs, batch_size):\n",
    "    for epoch in trange(epochs, desc=\"Training\", bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % ('\\033[1;35m', '\\033[0m')):\n",
    "        permutation = torch.randperm(X_combined.size()[0])\n",
    "\n",
    "        for i in range(0, X_combined.size()[0], batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = X_combined[indices], targets_zero_inflation[indices]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            zero_inflation, positive_expression = model(batch_x)\n",
    "\n",
    "            loss_zero_inflation = nn.BCELoss()(zero_inflation, batch_y)\n",
    "            loss_positive_expression = nn.MSELoss()(positive_expression, batch_y)\n",
    "\n",
    "            loss = loss_zero_inflation + loss_positive_expression\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "n_genes = adata.shape[1]\n",
    "print(n_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MASTModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_input \u001b[39m=\u001b[39m X_combined\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m MASTModel(n_input, n_genes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MASTModel' is not defined"
     ]
    }
   ],
   "source": [
    "n_input = X_combined.size()[1]\n",
    "model = MASTModel(n_input, n_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "train(model, optimizer, X_combined, targets_zero_inflation, epochs, batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, targets_zero_inflation, test_size = 0.3, random_state = 1712)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X_train, y_train, epochs, batch_size):\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in trange(epochs, desc=\"Training\", bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % ('\\033[1;34m', '\\033[0m')):\n",
    "        epoch_loss = 0\n",
    "        permutation = torch.randperm(X_train.size()[0])\n",
    "\n",
    "        for i in range(0, X_train.size()[0], batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = X_train[indices], y_train[indices]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            zero_inflation, positive_expression = model(batch_x)\n",
    "\n",
    "            loss_zero_inflation = nn.BCELoss()(zero_inflation, batch_y)\n",
    "            loss_positive_expression = nn.MSELoss()(positive_expression, batch_y)\n",
    "\n",
    "            loss = loss_zero_inflation + loss_positive_expression\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss /= (X_train.size()[0] / batch_size)\n",
    "        loss_history.append(epoch_loss)\n",
    "\n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_combined.shape[1]\n",
    "hidden_size = 128\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "model = MAST(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "loss_history = train(model, optimizer, X_train, y_train, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    with torch.no_grad():\n",
    "        zero_inflation, positive_expression = model(X)\n",
    "    return zero_inflation, positive_expression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_inflation_preds, positive_expression_preds = predict(model, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the predicted probabilities to binary values using a threshold of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_test_bin = (y_test.numpy() > threshold).astype(int)\n",
    "zero_inflation_preds_bin = (zero_inflation_preds.numpy() > threshold).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_bin, zero_inflation_preds_bin)\n",
    "precision = precision_score(y_test_bin, zero_inflation_preds_bin, average='macro', zero_division=0)\n",
    "recall = recall_score(y_test_bin, zero_inflation_preds_bin, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_test_bin, zero_inflation_preds_bin, average='macro', zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyMAST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
